{"cells":[{"cell_type":"markdown","metadata":{"id":"bX6Zgl4W9SnP"},"source":["# Purpose\n","The goal of this program is to capture and save the facial landmarks for each video into an NPY file\n","\n","For simplicity, we will only be converting the videos in the **MU3D** database."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0XYrniqgKrKs","outputId":"d101ba97-3151-4460-8ef4-54a311f4eaed","executionInfo":{"status":"ok","timestamp":1715488197575,"user_tz":240,"elapsed":43813,"user":{"displayName":"Hin Ho Shum","userId":"01694447193500416217"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Collecting mediapipe\n","  Downloading mediapipe-0.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n","Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26+cuda12.cudnn89)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.25.2)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n","Collecting protobuf<5,>=4.25.3 (from mediapipe)\n","  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sounddevice>=0.4.4 (from mediapipe)\n","  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n","Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.2.0)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.3.0)\n","Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.11.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n","Installing collected packages: protobuf, sounddevice, mediapipe\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed mediapipe-0.10.14 protobuf-4.25.3 sounddevice-0.4.6\n"]}],"source":["from google.colab import drive\n","from google.colab.patches import cv2_imshow\n","drive.mount('/content/drive')\n","\n","!pip3 install mediapipe\n","\n","import mediapipe as mp\n","from mediapipe.tasks import python\n","from mediapipe.tasks.python import vision\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import glob"]},{"cell_type":"markdown","metadata":{"id":"sADzVSYbpKgW"},"source":["# Obtaining the Truthfulness of Each Video\n","For the UMiami dataset (MU3D), the truthfulness of each video is saved in a separate Excel file. Therefore, we will first create a dictionary containing the truthfulness of each video. This will make it easier for later work because we won't have to search the Excel file each time we load a video."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"zRNsKXbFNgzL","executionInfo":{"status":"ok","timestamp":1715488204061,"user_tz":240,"elapsed":3221,"user":{"displayName":"Hin Ho Shum","userId":"01694447193500416217"}}},"outputs":[],"source":["FOLDER = '/content/drive/MyDrive/Deception_Detection/Datasets/MU3D-Package'\n","VIDEO_DATA_PATH = FOLDER + \"/\" + \"VideosMP4\"\n","EXCEL_DATA_PATH = FOLDER + \"/\"+ \"MU3D Codebook.xlsx\"\n","SAVE_NPY_PATH = FOLDER + \"/\" + \"NPY_FILES(240frames)\"\n","\n","df = pd.read_excel(EXCEL_DATA_PATH, sheet_name=\"Video-Level Data\")\n","\n","# Iterate through each row of the Excel file\n","truthfulness = {}\n","for index, row in df.iterrows():\n","  truthfulness[row[\"VideoID\"]] = row[\"Veracity\"]"]},{"cell_type":"markdown","metadata":{"id":"tHFC4c70O-3I"},"source":["# Finding the FPS and Duration for the videos in our dataset\n","Since micro-expressions last between 1/25 to 1/5 seconds. Our video frame rate (fps) must be high enough to capture them. Let's first try to find our the FPS and Duration for the videos in our dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ar5rcRLzOLFK","executionInfo":{"status":"ok","timestamp":1715488227268,"user_tz":240,"elapsed":17890,"user":{"displayName":"Hin Ho Shum","userId":"01694447193500416217"}}},"outputs":[],"source":["fpses = []\n","durations = []\n","\n","for file_path in glob.glob(VIDEO_DATA_PATH+\"/**\", recursive = True):\n","  # Skip non-videos\n","  if file_path[-4:] != \".mp4\":\n","    continue\n","\n","  # Create a Video Capture Object\n","  video = cv2.VideoCapture(file_path)\n","\n","  # Find the FPS of the video\n","  fps = video.get(cv2.CAP_PROP_FPS)\n","  fpses.append(fps)\n","\n","  # Calculate the duration of the video in seconds\n","  frame_count = video.get(cv2.CAP_PROP_FRAME_COUNT)\n","  duration = frame_count / fps\n","  durations.append(duration)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":162,"status":"ok","timestamp":1715488236497,"user":{"displayName":"Hin Ho Shum","userId":"01694447193500416217"},"user_tz":240},"id":"N5nwFsecDjfc","outputId":"4b152a5b-a831-44bd-dea6-7555d7eff717"},"outputs":[{"output_type":"stream","name":"stdout","text":["Average FPS: 29.98\n","Max FPS: 30.00\n","Min FPS: 29.97\n","\n","Average Duration: 35.76\n","Max Duration: 57.79\n","Min Duration: 10.01\n"]}],"source":["from statistics import mean\n","print(f\"Average FPS: {mean(fpses):.2f}\")\n","print(f\"Max FPS: {max(fpses):.2f}\")\n","print(f\"Min FPS: {min(fpses):.2f}\")\n","\n","print()\n","print(f\"Average Duration: {mean(durations):.2f}\")\n","print(f\"Max Duration: {max(durations):.2f}\")\n","print(f\"Min Duration: {min(durations):.2f}\")"]},{"cell_type":"markdown","metadata":{"id":"0rermLEUEDot"},"source":["# Note\n","Based on the results, the MU3D videos generally has a higher FPS than those in the Trial dataset.<br>\n","We have decided to collect a frame every 0.10 seconds.<br>\n","For a video that has 25 frames per second, we will collect every 5th frame.<br>\n","For a video that has 10 frames per second, we will collect every frame."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"yOkGdR3mR3nw","executionInfo":{"status":"ok","timestamp":1715488409273,"user_tz":240,"elapsed":145,"user":{"displayName":"Hin Ho Shum","userId":"01694447193500416217"}}},"outputs":[],"source":["import sys\n","\n","def detectLandmarks(RGBinput):\n","  # STEP 1: Create an FaceLandmarker object.\n","  base_options = python.BaseOptions(model_asset_path='/content/drive/MyDrive/Deception_Detection/Code/face_landmarker.task')\n","  options = vision.FaceLandmarkerOptions(base_options=base_options,\n","                                        output_face_blendshapes=True,\n","                                        output_facial_transformation_matrixes=True,\n","                                        num_faces=1)\n","  detector = vision.FaceLandmarker.create_from_options(options)\n","  # STEP 2: Load the input image.\n","  image = mp.Image(image_format=mp.ImageFormat.SRGB, data=RGBinput)\n","  # STEP 3: Detect face landmarks from the input image.\n","  detection_result = detector.detect(image)\n","\n","  return detection_result\n","\n","def normalized_landmarks_to_np_array(detection_result):\n","    normalized_landmarks = detection_result.face_landmarks[0]\n","\n","    #478 Landmarks, xyz coordinates\n","    landmarks_array = np.zeros((478, 2))  # Initialize array to hold x, y, z coordinates\n","\n","    for i, landmark in enumerate(normalized_landmarks):\n","        landmarks_array[i] = [landmark.x, landmark.y]\n","    return landmarks_array\n","\n","def video_to_numpy(video, veracity):\n","  fps = video.get(cv2.CAP_PROP_FPS)\n","  every_nth_frame = round(fps * 0.1)\n","\n","  count, success = 0, 1\n","  collected_frames = 0\n","\n","  arr_list = [] # A list containing the arrays of multiple frames\n","  while success and collected_frames < 240:\n","    success, frame = video.read()\n","    if success and count % every_nth_frame == 0:\n","      detection_result = detectLandmarks(frame)\n","      try:\n","        nparray = normalized_landmarks_to_np_array(detection_result)\n","        arr_list.append(nparray)\n","        collected_frames = collected_frames + 1\n","      except IndexError:\n","        # An index error indicates that there was a failure to capture the face\n","        continue\n","    count = count + 1\n","  return np.stack(arr_list)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"g2LXlcNNjQlv","executionInfo":{"status":"ok","timestamp":1715488884692,"user_tz":240,"elapsed":416,"user":{"displayName":"Hin Ho Shum","userId":"01694447193500416217"}}},"outputs":[],"source":["def file_exists(file_path):\n","    files = glob.glob(file_path)\n","    return len(files) > 0\n","\n","for file_path in glob.glob(VIDEO_DATA_PATH+\"/**\", recursive = True):\n","  # Skip non-videos\n","  if file_path[-4:] != \".mp4\":\n","    continue\n","\n","  # Skip videos that have already been converted to NPY format\n","  filename = file_path.split(\"/\")[-1][:-4]\n","  newfilepath = SAVE_NPY_PATH + \"/\" + f'{filename}.npy'\n","  if file_exists(newfilepath):\n","    continue\n","\n","  # Create a Video Capture Object\n","  video = cv2.VideoCapture(file_path)\n","\n","  # Truthness of the Speaker in Video\n","  veracity = truthfulness[filename]\n","\n","  stacked_array = video_to_numpy(video, veracity)\n","  print(stacked_array.shape)\n","  np.save(newfilepath, stacked_array)"]},{"cell_type":"code","source":[],"metadata":{"id":"oansuT-rE8xR"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}